{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic Task Evals\n",
    "\n",
    "This notebook runs the diagnostic task evals for the models reported in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_model_evals(tasks_and_models, model_class, random_seed=59):\n",
    "    # Loop through the list and run the eval script with each parameter\n",
    "    for task in tasks_and_models.keys():\n",
    "        models = tasks_and_models[task]\n",
    "        for model in models:\n",
    "            command = f\"python diagnostic_task_eval.py {task} {model} {model_class} --random_seed {random_seed}\"\n",
    "            # Execute the command using subprocess.run\n",
    "            subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "vowel_removal\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/vowel_removal/T5/t5_simple_vowel_removal_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading vowel_removal test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:28<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.0005509855701238849\n",
      "Eval percent deleted tokens: 0.0\n",
      "Eval new sequence length: 128.0\n",
      "Eval token accuracy: 0.99972265625\n",
      "Eval sequence accuracy: 0.96534375\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "contextual_vowel_removal\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/contextual_vowel_removal/T5/t5_contextual_vowel_removal_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading contextual_vowel_removal test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:30<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.00017452824787233113\n",
      "Eval percent deleted tokens: 0.0\n",
      "Eval new sequence length: 128.0\n",
      "Eval token accuracy: 0.999933349609375\n",
      "Eval sequence accuracy: 0.99153125\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "merge_ABC\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/merge_ABC/T5/t5_merge_ABC_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading merge_ABC test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:29<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.00026714385767627393\n",
      "Eval percent deleted tokens: 0.0\n",
      "Eval new sequence length: 128.0\n",
      "Eval token accuracy: 0.99987744140625\n",
      "Eval sequence accuracy: 0.9844375\n",
      "Examples evaluated: 32000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of parameters you want to loop through\n",
    "tasks_and_models = {\n",
    "    \"vowel_removal\": [\"t5_simple_vowel_removal\"],\n",
    "    \"contextual_vowel_removal\": [\"t5_contextual_vowel_removal\"],\n",
    "    \"merge_ABC\": [\"t5_merge_ABC\"],\n",
    "}\n",
    "\n",
    "run_model_evals(tasks_and_models, \"T5\", random_seed=59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MrT5 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "vowel_removal\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/vowel_removal/MrT5/mrt5_simple_vowel_removal_0.0_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading vowel_removal test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:28<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 9.813663885506685e-05\n",
      "Eval percent deleted tokens: 18.9471435546875\n",
      "Eval new sequence length: 114.564\n",
      "Eval token accuracy: 0.999973388671875\n",
      "Eval sequence accuracy: 0.9966875\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "vowel_removal\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/vowel_removal/MrT5/mrt5_simple_vowel_removal_0.0001_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading vowel_removal test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:24<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.008236341631039977\n",
      "Eval percent deleted tokens: 51.1510986328125\n",
      "Eval new sequence length: 76.956\n",
      "Eval token accuracy: 0.997520263671875\n",
      "Eval sequence accuracy: 0.781625\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "contextual_vowel_removal\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/contextual_vowel_removal/MrT5/mrt5_contextual_vowel_removal_0.001_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading contextual_vowel_removal test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.0003811254109177753\n",
      "Eval percent deleted tokens: 1.5625\n",
      "Eval new sequence length: 126.0\n",
      "Eval token accuracy: 0.999878173828125\n",
      "Eval sequence accuracy: 0.9844375\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "contextual_vowel_removal\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/contextual_vowel_removal/MrT5/mrt5_contextual_vowel_removal_0.001_L7_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading contextual_vowel_removal test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:30<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.0010879925589688355\n",
      "Eval percent deleted tokens: 18.51201171875\n",
      "Eval new sequence length: 120.16\n",
      "Eval token accuracy: 0.999718994140625\n",
      "Eval sequence accuracy: 0.964875\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "contextual_vowel_removal\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/contextual_vowel_removal/MrT5/mrt5_contextual_vowel_removal_0.001_L8_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading contextual_vowel_removal test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:31<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.0015164393637678586\n",
      "Eval percent deleted tokens: 18.51201171875\n",
      "Eval new sequence length: 120.152\n",
      "Eval token accuracy: 0.99959228515625\n",
      "Eval sequence accuracy: 0.9491875\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "merge_ABC\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/merge_ABC/MrT5/mrt5_merge_ABC_0.001_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading merge_ABC test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:31<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.00024240130726866483\n",
      "Eval percent deleted tokens: 1.5625\n",
      "Eval new sequence length: 126.0\n",
      "Eval token accuracy: 0.99991259765625\n",
      "Eval sequence accuracy: 0.988875\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "merge_ABC\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/merge_ABC/MrT5/mrt5_merge_ABC_0.001_L6_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading merge_ABC test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:30<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.0004778707785771985\n",
      "Eval percent deleted tokens: 8.305029296875\n",
      "Eval new sequence length: 126.0\n",
      "Eval token accuracy: 0.9998212890625\n",
      "Eval sequence accuracy: 0.97740625\n",
      "Examples evaluated: 32000\n",
      "\n",
      "Loading model...\n",
      "merge_ABC\n",
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/merge_ABC/MrT5/mrt5_merge_ABC_0.001_L7_seed59/checkpoints/checkpoint-20000\n",
      "\n",
      "Loading merge_ABC test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [01:30<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval cross entropy loss: 0.004423437299672514\n",
      "Eval percent deleted tokens: 16.936083984375\n",
      "Eval new sequence length: 124.452\n",
      "Eval token accuracy: 0.998436767578125\n",
      "Eval sequence accuracy: 0.85221875\n",
      "Examples evaluated: 32000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of parameters you want to loop through\n",
    "tasks_and_models = {\n",
    "    \"vowel_removal\":\n",
    "      [\n",
    "        \"mrt5_simple_vowel_removal_0.0\",\n",
    "        \"mrt5_simple_vowel_removal_0.0001\",\n",
    "      ],\n",
    "    \"contextual_vowel_removal\":\n",
    "      [\n",
    "        \"mrt5_contextual_vowel_removal_0.001\",\n",
    "        \"mrt5_contextual_vowel_removal_0.001_L7\",\n",
    "        \"mrt5_contextual_vowel_removal_0.001_L8\",\n",
    "      ],\n",
    "    \"merge_ABC\":\n",
    "      [\n",
    "        \"mrt5_merge_ABC_0.001\",\n",
    "        \"mrt5_merge_ABC_0.001_L6\",\n",
    "        \"mrt5_merge_ABC_0.001_L7\",\n",
    "      ],\n",
    "}\n",
    "\n",
    "run_model_evals(tasks_and_models, \"MrT5\", random_seed=59)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charlm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
