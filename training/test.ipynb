{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/kallini/miniconda3/envs/charlm-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /nlp/scr3/nlp/llms-in-llms/mrt5/models/vowel_removal/MrT5/simple_vowel_removal_pctrl20%_seed85_seed85/checkpoints/checkpoint-10000\n"
     ]
    }
   ],
   "source": [
    "from utils import load_model_from_path\n",
    "\n",
    "path = \"/nlp/scr3/nlp/llms-in-llms/mrt5/models/vowel_removal/MrT5/simple_vowel_removal_pctrl20%_seed85_seed85/checkpoints/checkpoint-10000\"\n",
    "model = load_model_from_path(\"MrT5\", model_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"/nlp/scr3/nlp/llms-in-llms/mrt5/models/vowel_removal/MrT5/simple_vowel_removal_pctrl20%_seed85_seed85/checkpoints/checkpoint-10000\",\n",
       "  \"architectures\": [\n",
       "    \"MrT5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_ff\": 1024,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"delete_gate_layer\": 2,\n",
       "  \"deletion_threshold\": -15.0,\n",
       "  \"deletion_type\": \"scaled_sigmoid\",\n",
       "  \"dense_act_fn\": \"gelu_new\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"eval_language\": \"en\",\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"fixed_deletion_amount\": 0.5,\n",
       "  \"gate_layer_norm\": true,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"has_absolute_position_embeddings\": false,\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_heads\": 4,\n",
       "  \"num_decoder_layers\": 3,\n",
       "  \"num_heads\": 6,\n",
       "  \"num_layers\": 3,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"random_deletion_probability\": 0.5,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"sigmoid_mask_scale\": -30.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"tokenizer_class\": \"ByT5Tokenizer\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"train_language\": \"en\",\n",
       "  \"transformers_version\": \"4.39.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_gumbel_noise\": true,\n",
       "  \"use_softmax1\": true,\n",
       "  \"vocab_size\": 384\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/kallini/miniconda3/envs/charlm-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer(\"akjefjklsdafka\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[100, 110, 109, 104, 105, 109, 110, 111, 118, 103, 100, 105, 110, 100,\n",
       "           1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = model(input_ids=encoded[\"input_ids\"], decoder_input_ids=encoded[\"input_ids\"], output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_norms = []\n",
    "for k, q in zip(output_ids.cross_attention_keys, output_ids.cross_attention_queries):\n",
    "    mean_norms.append(q.norm(dim=-1).mean() + k.norm(dim=-1).mean())\n",
    "for k, q in zip(output_ids.encoder_keys[2:], output_ids.encoder_queries[2:]):\n",
    "    mean_norms.append(q.norm(dim=-1).mean() + k.norm(dim=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.6549, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mean_norms) / len(mean_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids.decoder_scores[0].norm(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"/nlp/scr3/nlp/llms-in-llms/mrt5/models/contextual_vowel_removal/MrT5/test_contextual_randomk_gumbel_seed68/checkpoints/checkpoint-30000\",\n",
       "  \"architectures\": [\n",
       "    \"MrT5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_ff\": 1024,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"delete_gate_layer\": 2,\n",
       "  \"deletion_threshold\": -15.0,\n",
       "  \"deletion_top_k\": 5,\n",
       "  \"deletion_type\": \"scaled_sigmoid\",\n",
       "  \"dense_act_fn\": \"gelu_new\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"eval_language\": \"en\",\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"fixed_deletion_amount\": 0.5,\n",
       "  \"gate_layer_norm\": true,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"has_absolute_position_embeddings\": false,\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"num_decoder_layers\": 3,\n",
       "  \"num_heads\": 6,\n",
       "  \"num_layers\": 3,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"random_deletion_probability\": 0.5,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"sigmoid_mask_scale\": -30.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"tokenizer_class\": \"ByT5Tokenizer\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"train_language\": \"en\",\n",
       "  \"transformers_version\": \"4.39.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_gumbel_noise\": true,\n",
       "  \"use_softmax1\": true,\n",
       "  \"vocab_size\": 384\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines: 10240000it [19:02, 8961.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language counts: {'fr': 683730, 'zh': 682190, 'vi': 682180, 'ru': 684169, 'hi': 682658, 'th': 682419, 'de': 683293, 'tr': 683178, 'ur': 682582, 'bg': 681281, 'es': 682210, 'sw': 681677, 'ar': 683507, 'en': 682630, 'el': 682296}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_languages(json_file):\n",
    "    language_count = {}\n",
    "\n",
    "    with open(json_file, 'r') as file:\n",
    "        # Create a progress bar for the file with `tqdm`\n",
    "        for line in tqdm(file, desc=\"Processing lines\"):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                # Check if the 'language' key exists in the JSON object\n",
    "                if 'language' in data:\n",
    "                    language = data['language']\n",
    "                    if language in language_count:\n",
    "                        language_count[language] += 1\n",
    "                    else:\n",
    "                        language_count[language] = 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error decoding JSON on this line:\", line)\n",
    "\n",
    "    return language_count\n",
    "\n",
    "# Usage example, replace 'your_file.json' with your actual JSON file path\n",
    "file_path = '/nlp/scr3/nlp/llms-in-llms/mrt5/lm_datasets/mc4-multilingual-train.json'\n",
    "result = count_languages(file_path)\n",
    "print(\"Language counts:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charlm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
